# fast_word_emotion_analysis

音声の入力を受けとり、音節の切れ目で、それまでの感情を計算します。  
arduinoを経由し、話を聞いてない人や耳が聞こえない人の首に電流を流して、感情に沿った適切なうなづきを実行させます。 
文字起こしの精度よりも、適切なうなづきを行うための、実行速度にリソースを割いています。  
arduinoのコードは……デモ機の中にしか残ってないかも。  

動作方法

srcの内部の二つのスクリプトを動作させる。二つとも、非同期で処理が走る。  
（それぞれ、分析の結果をfileのioを通してやりとりしている。理由はデモをする際に、支給されたパソコンのスペックがあんまりであったため、処理の負荷を手元の携帯に分散させることができるように、fileのio経由で同期させている。）  
初回は、whisperモデルやbertのモデルのダウンロードが走るため、時間がかかる。  
また、cudaや音声入力の管理が必要なため、環境依存で修正しなければならない諸々が非常に多い。  

androidのアプリでbluetooth経由で動くようにしたが……気が狂ってたので、アプリのコードもどっかやってしまった気がする。
